{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Redshift Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we illustrate how to copy data from Redshift to S3 and vice-versa.\n",
    "Prerequisites\n",
    "\n",
    "In order to successfully run this notebook, you'll first need to:\n",
    "1. Have a Redshift cluster within the same VPC.\n",
    "1. Preload that cluster with data from the iris data set in a table named public.irisdata.\n",
    "1. Update the credential file (redshift_creds_template.json.nogit) file with the appropriate information.\n",
    "\n",
    "Also, note that this Notebook instance needs to resolve to a private IP when connecting to the Redshift instance. There are two ways to resolve the Redshift DNS name to a private IP:\n",
    "1. The Redshift cluster is not publicly accessible so by default it will resolve to private IP.\n",
    "1. The Redshift cluster is publicly accessible and has an EIP associated with it but when accessed from within a VPC, it should resolve to private IP of the Redshift cluster. This is possible by setting following two VPC attributes to yes: DNS resolution and DNS hostnames. For instructions on setting that up, see Redshift public docs on Managing Clusters in an Amazon Virtual Private Cloud (VPC).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. log into redshift console\n",
    "\n",
    "2. quick launch cluster with single ds2.large node (try dc2 first, takes about 15 mins to launch)\n",
    "\n",
    "3. create a bucket called sagemaker-redshift-data and upload the iris.csv file\n",
    "\n",
    "4. remember to add redshiftFullAccess (or appropriate) to the Sagemaker notebook instance role\n",
    "\n",
    "5. Open the redshift master security group, and select an add new rule for inbound connections to the redshift_master securty group. Add the port 5439 and an appropriate inbound rule CIDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Setup\n",
    "Let's start by installing psycopg2, a PostgreSQL database adapter for the Python, adding a few imports and specifying a few configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs: \n",
      "    - psycopg2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    psycopg2-2.7.4             |   py36hb7f436b_0         292 KB  anaconda\n",
      "    certifi-2018.10.15         |           py36_0         139 KB  anaconda\n",
      "    ca-certificates-2018.03.07 |                0         124 KB  anaconda\n",
      "    openssl-1.0.2p             |       h14c3975_0         3.5 MB  anaconda\n",
      "    libpq-9.6.6                |       h1f21990_0         100 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    libpq:           9.6.6-h1f21990_0     anaconda   \n",
      "    psycopg2:        2.7.4-py36hb7f436b_0 anaconda   \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:         2018.8.24-py36_1     conda-forge --> 2018.10.15-py36_0 anaconda\n",
      "    openssl:         1.0.2p-h470a237_0    conda-forge --> 1.0.2p-h14c3975_0 anaconda\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    ca-certificates: 2018.8.24-ha4d7672_0 conda-forge --> 2018.03.07-0      anaconda\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "psycopg2-2.7.4       | 292 KB    | ##################################### | 100% \n",
      "certifi-2018.10.15   | 139 KB    | ##################################### | 100% \n",
      "ca-certificates-2018 | 124 KB    | ##################################### | 100% \n",
      "openssl-1.0.2p       | 3.5 MB    | ##################################### | 100% \n",
      "libpq-9.6.6          | 100 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c anaconda psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='sagemaker-redshift-data' # put your s3 bucket name here, and create s3 bucket\n",
    "prefix = ''\n",
    "# customize to your bucket where you have stored the data\n",
    "\n",
    "credfile = 'redshift_creds_template.json.nogit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(creds): \n",
    "    conn = psycopg2.connect(dbname=creds['db_name'], \n",
    "                            user=creds['username'], \n",
    "                            password=creds['password'],\n",
    "                            port=creds['port_num'],\n",
    "                            host=creds['host_name'])\n",
    "    return conn\n",
    "\n",
    "def get_df(creds, query):\n",
    "    with get_conn(creds) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            result_set = cur.fetchall()\n",
    "            colnames = [desc.name for desc in cur.description]\n",
    "            df = pd.DataFrame.from_records(result_set, columns=colnames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from Redshift\n",
    "\n",
    "We store the information needed to connect to Redshift in a credentials file. See the file `redshift_creds_template.json.nogit` for an example. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Edit the redshift_creds_template.json.nogit to include your cluster's details in \n",
    "{\n",
    "    \"host_name\": \"redshift-cluster-1.cscmhyvnqsan.us-east-2.redshift.amazonaws.com\",\n",
    "    \"port_num\": \"5439\",\n",
    "    \"db_name\": \"dev\",\n",
    "    \"username\": \"awsuser\",\n",
    "    \"password\": \"Password1\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"host_name\": \"redshift-cluster-1.cscmhyvnqsan.us-east-2.redshift.amazonaws.com\",\r\n",
      "    \"port_num\": \"5439\",\r\n",
      "    \"db_name\": \"dev\",\r\n",
      "    \"username\": \"awsuser\",\r\n",
      "    \"password\": \"Password1\"\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat redshift_creds_template.json.nogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read credentials to a dictionary\n",
    "with open(credfile) as fh:\n",
    "    creds = json.loads(fh.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4551  100  4551    0     0   8785      0 --:--:-- --:--:-- --:--:--  8785\n"
     ]
    }
   ],
   "source": [
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data --output ./iris2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "localFile = 'iris2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to S3...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing to S3...\")\n",
    "\n",
    "fObj = open(localFile, 'rb')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, localFile)).upload_fileobj(fObj)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from S3...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading from S3...\")\n",
    "# key unchanged for demo purposes - change key to read from output data\n",
    "key = os.path.join(prefix, localFile)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "outfile = 'iris2.csv'\n",
    "s3.Bucket(bucket).download_file(key, outfile)\n",
    "df2 = pd.read_csv(outfile)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to Redshift...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing to Redshift...\")\n",
    "\n",
    "connection_str = 'postgresql+psycopg2://' + \\\n",
    "                  creds['username'] + ':' + \\\n",
    "                  creds['password'] + '@' + \\\n",
    "                  creds['host_name'] + ':' + \\\n",
    "                  creds['port_num'] + '/' + \\\n",
    "                  creds['db_name'];\n",
    "                    \n",
    "df2.to_sql('irisdata_v2', connection_str, schema='public', index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the copied data in Redshift - success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data using pandas read_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  iris-setosa\n",
       "0  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "1  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "2  5.4  3.9  1.7  0.4  Iris-setosa\n",
       "3  4.8  3.4  1.6  0.2  Iris-setosa\n",
       "4  5.8  4.0  1.2  0.2  Iris-setosa"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "conn = get_conn(creds)\n",
    "query = 'select * from irisdata_v2'\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data using our custom wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from Redshift...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  iris-setosa\n",
       "0  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "1  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "2  5.4  3.9  1.7  0.4  Iris-setosa\n",
       "3  4.8  3.4  1.6  0.2  Iris-setosa\n",
       "4  5.8  4.0  1.2  0.2  Iris-setosa"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reading from Redshift...\")\n",
    "df = get_df(creds, query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results of \"inference\" to another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving file\")\n",
    "localFile = 'iris_read.csv'\n",
    "df.to_csv(localFile, index=False)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
